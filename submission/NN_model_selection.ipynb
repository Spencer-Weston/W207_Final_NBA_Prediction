{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf15e3d-3c97-45bd-839f-258ae71c4b8f",
   "metadata": {},
   "source": [
    "# Final Neural Network Model Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c103f99e-883e-497d-9146-2fa20f0dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from  IPython import display\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51afa891-7729-47d4-a6d7-578c609c40af",
   "metadata": {},
   "source": [
    "Ensure the random state is consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43642f2a-36e9-4030-878c-270676c6bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e81c9ea5-630d-45f4-a295-1dc3731df15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a97924-ecaa-43c9-a5b5-afa590695f6e",
   "metadata": {},
   "source": [
    "### Data loading, transformation, and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97288e76-f745-4c1b-abd5-9d14bb6630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/nba_final_data.csv\")\n",
    "data = data.sample(frac=1, random_state = 42) # Shuffle data\n",
    "y = data['PLUS_MINUS_HOME']\n",
    "X = data.drop(['GAME_ID', \"TEAM_ID_HOME\", \"TEAM_ID_AWAY\", \"GAME_DATE\", \"SEASON\",\n",
    "               \"PLUS_MINUS_HOME\", \"MIN_HOME\", 'WL_Home_modified'], axis=1)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8de01-dd96-4855-a616-9e068aa0bb20",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66f940e4-07fb-42e1-8c33-3f6e22047f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log dir \n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da0b7dfa-4abf-4ab5-9849-02419c49da97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # hyperparameter boolean for performing dropout \n",
    "    dropout = hp.Boolean(\"dropout\") \n",
    "    # hyperparameter for percent of units to dropout \n",
    "    if dropout:\n",
    "        drop_percent = hp.Choice(\"drop_percent\", [0.05, 0.1, 0.25, 0.5])\n",
    "        \n",
    "    kernel_regularizer= regularizers.l2(0.001)\n",
    "    \n",
    "    # hyperparameter for choice of regularization strength\n",
    "    regularization = hp.Choice(\"regularization_strength\", [0.0001, 0.001, 0.01, 0.1, 0.25, 0.5])\n",
    "    \n",
    "    model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        hp_units = hp.Int('units', min_value=8, max_value=64, step=4)\n",
    "        model.add(\n",
    "            keras.layers.Dense(units=hp_units,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer = regularizers.l2(regularization))\n",
    "        )\n",
    "        # Add dropout layer if dropout hyperparameter is True\n",
    "        if dropout:\n",
    "            keras.layers.Dropout(drop_percent)\n",
    "            \n",
    "    model.add(keras.layers.Dense(1)) # output layer\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2898ea5-cca0-40d1-b022-826dbe35ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name):\n",
    "    return [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25),\n",
    "    tf.keras.callbacks.TensorBoard(logdir/name)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc3b810f-2c4c-44b4-8261-e5e9cc6bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(model_builder,\n",
    "                                objective='val_mse',\n",
    "                                max_trials = 100,\n",
    "                                seed=42,\n",
    "                                overwrite=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef012a-f7c5-40dc-97db-20395d307b76",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Search for Parameters\n",
    "Here, we search for the best set of hyperparameters with the tuner, extract the hyperparemeters, and build a model with the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c01e3241-9cfd-496e-82ed-fd630e14eff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 01m 11s]\n",
      "val_mse: 149.70858764648438\n",
      "\n",
      "Best val_mse So Far: 148.43832397460938\n",
      "Total elapsed time: 01h 53m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=200, validation_split=0.2, callbacks=get_callbacks('tuner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "591a5678-925e-4f9b-8eaf-48ebb676e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameter model\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build and save it for future use \n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "416a8440-c1b7-450b-a5e3-ec7978e99cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "Num_layers: 1\n",
      "Num_units: 36\n",
      "Dropout: False\n",
      "Dropout rate: 0.25\n",
      "Regularization strength: 0.25\n",
      "Learning Rate: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Num_layers: {best_hps.get('num_layers')}\n",
    "Num_units: {best_hps.get('units')}\n",
    "Dropout: {best_hps.get('dropout')}\n",
    "Dropout rate: {best_hps.get('drop_percent')}\n",
    "Regularization strength: {best_hps.get(\"regularization_strength\")}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97243a0-8f86-4b81-a5fd-9c83ff33c3e3",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Refit and Epoch Selection\n",
    "Now that we have the best hyperparameters, we refit the model. To determine the optimal number of training epochs, we find the epoch number of the best results as determined by mean square error on the validation set. Finally, we rebuild the model from the hyperparameters, specify the number of epochs as determined by the validation mean square error, and refit the model with the full training data set (train + validation). Then, test results are reported in the final cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8f75f9f-3bc4-45d2-bb89-5a393cd3c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:166.2021,  mse:160.9939,  val_loss:158.9273,  val_mse:155.1157,  \n",
      ".................................................."
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train,\n",
    "                            epochs=300,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=0,\n",
    "                            callbacks=get_callbacks('best_model_epoch_selection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ceaa400-a09c-4124-b126-e9f2bf2f2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE: 148.5083465576172\n"
     ]
    }
   ],
   "source": [
    "validation_mse = history.history['val_mse']\n",
    "min_mse = min(validation_mse)\n",
    "min_idx = validation_mse.index(min_mse)\n",
    "num_epochs = min_idx\n",
    "print(f\"Minimum MSE: {min_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29387608-229d-40e3-8936-be98879bd12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "  1/416 [..............................] - ETA: 1:29 - loss: 136.9982 - mse: 125.4426WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.\n",
      "406/416 [============================>.] - ETA: 0s - loss: 163.7635 - mse: 158.9777\n",
      "Epoch: 0, loss:163.8388,  mse:159.0725,  \n",
      ".WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 1s 766us/step - loss: 163.8388 - mse: 159.0725\n",
      "Epoch 2/38\n",
      "356/416 [========================>.....] - ETA: 0s - loss: 159.5364 - mse: 156.0221.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 916us/step - loss: 160.6180 - mse: 157.1347\n",
      "Epoch 3/38\n",
      "363/416 [=========================>....] - ETA: 0s - loss: 159.9836 - mse: 156.8698.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 776us/step - loss: 159.4421 - mse: 156.2965\n",
      "Epoch 4/38\n",
      "348/416 [========================>.....] - ETA: 0s - loss: 161.0695 - mse: 157.9883.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 782us/step - loss: 158.9559 - mse: 155.8466\n",
      "Epoch 5/38\n",
      "388/416 [==========================>...] - ETA: 0s - loss: 158.4121 - mse: 155.4275.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 731us/step - loss: 158.3138 - mse: 155.3365\n",
      "Epoch 6/38\n",
      "391/416 [===========================>..] - ETA: 0s - loss: 157.9324 - mse: 155.0911.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 710us/step - loss: 157.7860 - mse: 154.9476\n",
      "Epoch 7/38\n",
      "389/416 [===========================>..] - ETA: 0s - loss: 157.2357 - mse: 154.4807.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 721us/step - loss: 157.2583 - mse: 154.5086\n",
      "Epoch 8/38\n",
      "359/416 [========================>.....] - ETA: 0s - loss: 158.6258 - mse: 155.7010.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 780us/step - loss: 157.4098 - mse: 154.4004\n",
      "Epoch 9/38\n",
      "381/416 [==========================>...] - ETA: 0s - loss: 157.9577 - mse: 155.1319.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 752us/step - loss: 157.1391 - mse: 154.3284\n",
      "Epoch 10/38\n",
      "398/416 [===========================>..] - ETA: 0s - loss: 156.8089 - mse: 154.0776.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 728us/step - loss: 157.0628 - mse: 154.3149\n",
      "Epoch 11/38\n",
      "385/416 [==========================>...] - ETA: 0s - loss: 157.7661 - mse: 154.8684.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 743us/step - loss: 157.1623 - mse: 154.2864\n",
      "Epoch 12/38\n",
      "394/416 [===========================>..] - ETA: 0s - loss: 156.8663 - mse: 154.0987.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 741us/step - loss: 156.8849 - mse: 154.0853\n",
      "Epoch 13/38\n",
      "376/416 [==========================>...] - ETA: 0s - loss: 157.7040 - mse: 154.7079.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 747us/step - loss: 157.3888 - mse: 154.4284\n",
      "Epoch 14/38\n",
      "414/416 [============================>.] - ETA: 0s - loss: 156.7774 - mse: 153.9895.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 817us/step - loss: 156.8745 - mse: 154.0871\n",
      "Epoch 15/38\n",
      "406/416 [============================>.] - ETA: 0s - loss: 157.3825 - mse: 154.2092.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 845us/step - loss: 157.4605 - mse: 154.2961\n",
      "Epoch 16/38\n",
      "361/416 [=========================>....] - ETA: 0s - loss: 157.4229 - mse: 154.5719.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 999us/step - loss: 156.9937 - mse: 154.1630\n",
      "Epoch 17/38\n",
      "401/416 [===========================>..] - ETA: 0s - loss: 156.9556 - mse: 154.3097.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 755us/step - loss: 156.9255 - mse: 154.2708\n",
      "Epoch 18/38\n",
      "407/416 [============================>.] - ETA: 0s - loss: 155.9672 - mse: 153.0919.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 831us/step - loss: 156.5316 - mse: 153.6535\n",
      "Epoch 19/38\n",
      "411/416 [============================>.] - ETA: 0s - loss: 156.7334 - mse: 153.7024.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 730us/step - loss: 157.0462 - mse: 154.0223\n",
      "Epoch 20/38\n",
      "359/416 [========================>.....] - ETA: 0s - loss: 154.9629 - mse: 152.4359.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 920us/step - loss: 156.2358 - mse: 153.6660\n",
      "Epoch 21/38\n",
      "378/416 [==========================>...] - ETA: 0s - loss: 157.6166 - mse: 154.7480.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 763us/step - loss: 156.9580 - mse: 154.0894\n",
      "Epoch 22/38\n",
      "411/416 [============================>.] - ETA: 0s - loss: 157.2202 - mse: 154.2694.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 954us/step - loss: 157.1452 - mse: 154.1931\n",
      "Epoch 23/38\n",
      "365/416 [=========================>....] - ETA: 0s - loss: 156.4678 - mse: 153.4545.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 832us/step - loss: 156.8050 - mse: 153.8320\n",
      "Epoch 24/38\n",
      "359/416 [========================>.....] - ETA: 0s - loss: 154.2581 - mse: 151.7432.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 763us/step - loss: 156.2805 - mse: 153.6534\n",
      "Epoch 25/38\n",
      "377/416 [==========================>...] - ETA: 0s - loss: 156.6627 - mse: 153.7257.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 802us/step - loss: 156.7482 - mse: 153.8532\n",
      "Epoch 26/38\n",
      "366/416 [=========================>....] - ETA: 0s - loss: 156.6957 - mse: 153.8093.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 760us/step - loss: 156.8456 - mse: 153.9217\n",
      "Epoch 27/38\n",
      "364/416 [=========================>....] - ETA: 0s - loss: 157.0241 - mse: 154.3390.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 763us/step - loss: 156.4355 - mse: 153.7781\n",
      "Epoch 28/38\n",
      "381/416 [==========================>...] - ETA: 0s - loss: 157.7016 - mse: 154.9140.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 791us/step - loss: 156.5951 - mse: 153.8134\n",
      "Epoch 29/38\n",
      "379/416 [==========================>...] - ETA: 0s - loss: 156.9671 - mse: 154.2237.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 759us/step - loss: 156.5897 - mse: 153.8682\n",
      "Epoch 30/38\n",
      "401/416 [===========================>..] - ETA: 0s - loss: 155.8350 - mse: 152.9578.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 764us/step - loss: 156.6183 - mse: 153.7421\n",
      "Epoch 31/38\n",
      "392/416 [===========================>..] - ETA: 0s - loss: 157.4056 - mse: 154.4543.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 767us/step - loss: 157.0161 - mse: 154.0900\n",
      "Epoch 32/38\n",
      "372/416 [=========================>....] - ETA: 0s - loss: 156.4282 - mse: 153.9460.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 745us/step - loss: 156.2843 - mse: 153.7824\n",
      "Epoch 33/38\n",
      "390/416 [===========================>..] - ETA: 0s - loss: 156.7407 - mse: 153.9143.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 779us/step - loss: 156.6477 - mse: 153.8097\n",
      "Epoch 34/38\n",
      "366/416 [=========================>....] - ETA: 0s - loss: 157.6136 - mse: 154.7733.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 740us/step - loss: 156.8847 - mse: 154.0391\n",
      "Epoch 35/38\n",
      "365/416 [=========================>....] - ETA: 0s - loss: 156.3189 - mse: 153.8662.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 783us/step - loss: 156.2793 - mse: 153.7792\n",
      "Epoch 36/38\n",
      "358/416 [========================>.....] - ETA: 0s - loss: 156.5118 - mse: 153.6660.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 781us/step - loss: 156.6027 - mse: 153.7931\n",
      "Epoch 37/38\n",
      "366/416 [=========================>....] - ETA: 0s - loss: 156.2568 - mse: 153.8966.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 751us/step - loss: 156.1584 - mse: 153.8016\n",
      "Epoch 38/38\n",
      "406/416 [============================>.] - ETA: 0s - loss: 156.3950 - mse: 153.8041.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 872us/step - loss: 156.5399 - mse: 153.9527\n",
      "INFO:tensorflow:Assets written to: final_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history=best_model.fit(X_train, y_train, epochs=num_epochs, callbacks=get_callbacks('best_model'))\n",
    "best_model.save('final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b92b634c-b178-45e7-ab01-4296e8d14edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 484us/step - loss: 154.7836 - mse: 152.3198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 154.7836151123047, 'mse': 152.31983947753906}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = best_model.evaluate(X_test, y_test)\n",
    "dict(zip(best_model.metrics_names, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee1d5194-9bcf-4a91-9a82-b01851aece84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.577,  -9.577,  20.423, ...,  14.423,   5.423, -13.577],\n",
       "       [ -7.921, -16.921,  13.079, ...,   7.079,  -1.921, -20.921],\n",
       "       [-10.2  , -19.2  ,  10.8  , ...,   4.8  ,  -4.2  , -23.2  ],\n",
       "       ...,\n",
       "       [-14.795, -23.795,   6.205, ...,   0.205,  -8.795, -27.795],\n",
       "       [-13.456, -22.456,   7.544, ...,   1.544,  -7.456, -26.456],\n",
       "       [-14.151, -23.151,   6.849, ...,   0.849,  -8.151, -27.151]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_model.predict(X_test)\n",
    "pred - np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27437b76-8de4-4243-8357-0bdb09196f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_pred, y_actual):\n",
    "    \"\"\"\n",
    "    returns evaluation metrics for the model:\n",
    "    Accuracy, F1 Score, R Squre, RMSe\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    f1score = 0\n",
    "    rmse = 0\n",
    "    r_sqaure = 0\n",
    "    \n",
    "    if len(y_pred) != len(y_actual):\n",
    "        print('predicted and actual length not equal')\n",
    "        \n",
    "    else:\n",
    "        len_y = len(y_pred)\n",
    "        \n",
    "        y_pred_bool =  y_pred >= 0\n",
    "        y_actual_bool =  y_actual >= 0\n",
    "        f1score = f1_score(y_actual_bool, y_pred_bool, average='binary')\n",
    "        acc = accuracy_score(y_actual_bool, y_pred_bool)\n",
    "        \n",
    "        rmse = np.sqrt(mse(y_actual, y_pred))\n",
    "        r_sqaure = r2_score(y_actual, y_pred)\n",
    "        \n",
    "    df_evaluation = pd.DataFrame({'Accuracy': pd.Series(acc),\n",
    "                                 'F1 Score': pd.Series(f1score),\n",
    "                                 'R Square': pd.Series(r_sqaure),\n",
    "                                 'RMSE': pd.Series(rmse)})\n",
    "    return(df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e05168ee-5361-48c5-b281-af209ea0e920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>R Square</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631199</td>\n",
       "      <td>0.718125</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>12.341792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 Score  R Square       RMSE\n",
       "0  0.631199  0.718125    0.1166  12.341792"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(pred, np.array(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
