{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf15e3d-3c97-45bd-839f-258ae71c4b8f",
   "metadata": {},
   "source": [
    "# Final Neural Network Model Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c103f99e-883e-497d-9146-2fa20f0dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from  IPython import display\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51afa891-7729-47d4-a6d7-578c609c40af",
   "metadata": {},
   "source": [
    "Ensure the random state is consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43642f2a-36e9-4030-878c-270676c6bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81c9ea5-630d-45f4-a295-1dc3731df15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a97924-ecaa-43c9-a5b5-afa590695f6e",
   "metadata": {},
   "source": [
    "### Data loading, transformation, and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97288e76-f745-4c1b-abd5-9d14bb6630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/nba_final_data.csv\")\n",
    "data = data.sample(frac=1, random_state = 42) # Shuffle data\n",
    "y = data['PLUS_MINUS_HOME']\n",
    "X = data.drop(['GAME_ID', \"TEAM_ID_HOME\", \"TEAM_ID_AWAY\", \"GAME_DATE\", \"SEASON\",\n",
    "               \"PLUS_MINUS_HOME\", \"MIN_HOME\", 'WL_Home_modified'], axis=1)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8de01-dd96-4855-a616-9e068aa0bb20",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f940e4-07fb-42e1-8c33-3f6e22047f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log dir \n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0b7dfa-4abf-4ab5-9849-02419c49da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # hyperparameter boolean for performing dropout \n",
    "    dropout = hp.Boolean(\"dropout\") \n",
    "    # hyperparameter for percent of units to dropout \n",
    "    if dropout:\n",
    "        drop_percent = hp.Choice(\"drop_percent\", [0.1, 0.25, 0.5])\n",
    "        \n",
    "    kernel_regularizer= regularizers.l2(0.001)\n",
    "    \n",
    "    # hyperparameter for choice of regularization strength\n",
    "    regularization = hp.Choice(\"regularization_strength\", [0.0001, 0.001, 0.01])\n",
    "    \n",
    "    model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        hp_units = hp.Int('units', min_value=8, max_value=64, step=4)\n",
    "        model.add(\n",
    "            keras.layers.Dense(units=hp_units,\n",
    "                               activation='elu',\n",
    "                               kernel_regularizer = regularizers.l2(regularization))\n",
    "        )\n",
    "        # Add dropout layer if dropout hyperparameter is True\n",
    "        if dropout:\n",
    "            keras.layers.Dropout(drop_percent)\n",
    "            \n",
    "    model.add(keras.layers.Dense(1)) # output layer\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2898ea5-cca0-40d1-b022-826dbe35ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name):\n",
    "    return [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "    tf.keras.callbacks.TensorBoard(logdir/name)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3b810f-2c4c-44b4-8261-e5e9cc6bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(model_builder,\n",
    "                                objective='val_mse',\n",
    "                                max_trials = 500,\n",
    "                                seed=42,\n",
    "                                overwrite=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef012a-f7c5-40dc-97db-20395d307b76",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Search for Parameters\n",
    "Here, we search for the best set of hyperparameters with the tuner, extract the hyperparemeters, and build a model with the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01e3241-9cfd-496e-82ed-fd630e14eff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 500 Complete [00h 00m 14s]\n",
      "val_mse: 149.31893920898438\n",
      "\n",
      "Best val_mse So Far: 147.8925323486328\n",
      "Total elapsed time: 05h 52m 50s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=25, validation_split=0.2, callbacks=get_callbacks('tuner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591a5678-925e-4f9b-8eaf-48ebb676e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameter model\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build and save it for future use \n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416a8440-c1b7-450b-a5e3-ec7978e99cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "Num_layers: 3\n",
      "Num_units: 64\n",
      "Dropout: False\n",
      "Dropout rate: 0.5\n",
      "Regularization strength: 0.01\n",
      "Learning Rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Num_layers: {best_hps.get('num_layers')}\n",
    "Num_units: {best_hps.get('units')}\n",
    "Dropout: {best_hps.get('dropout')}\n",
    "Dropout rate: {best_hps.get('drop_percent')}\n",
    "Regularization strength: {best_hps.get(\"regularization_strength\")}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97243a0-8f86-4b81-a5fd-9c83ff33c3e3",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning With Bayesian Optimization: Refit and Epoch Selection\n",
    "Now that we have the best hyperparameters, we refit the model. To determine the optimal number of training epochs, we find the epoch number of the best results as determined by mean square error on the validation set. Finally, we rebuild the model from the hyperparameters, specify the number of epochs as determined by the validation mean square error, and refit the model with the full training data set (train + validation). Then, test results are reported in the final cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f75f9f-3bc4-45d2-bb89-5a393cd3c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:163.5843,  mse:161.7146,  val_loss:155.5696,  val_mse:153.7273,  \n",
      ".................................................."
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train,\n",
    "                            epochs=50,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=0,\n",
    "                            callbacks=get_callbacks('best_model_epoch_selection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ceaa400-a09c-4124-b126-e9f2bf2f2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE: 149.58773803710938\n"
     ]
    }
   ],
   "source": [
    "validation_mse = history.history['val_mse']\n",
    "min_mse = min(validation_mse)\n",
    "min_idx = validation_mse.index(min_mse)\n",
    "num_epochs = min_idx\n",
    "print(f\"Minimum MSE: {min_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29387608-229d-40e3-8936-be98879bd12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "  1/416 [..............................] - ETA: 2:06 - loss: 120.6341 - mse: 118.6991WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.\n",
      "368/416 [=========================>....] - ETA: 0s - loss: 162.4254 - mse: 160.5420\n",
      "Epoch: 0, loss:160.9637,  mse:159.0853,  \n",
      ".WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 1s 987us/step - loss: 160.9637 - mse: 159.0853\n",
      "Epoch 2/4\n",
      "402/416 [===========================>..] - ETA: 0s - loss: 155.6136 - mse: 153.7961.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 1ms/step - loss: 156.1774 - mse: 154.3605\n",
      "Epoch 3/4\n",
      "403/416 [============================>.] - ETA: 0s - loss: 154.1841 - mse: 152.3796.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 1ms/step - loss: 154.1140 - mse: 152.3093\n",
      "Epoch 4/4\n",
      "407/416 [============================>.] - ETA: 0s - loss: 152.9198 - mse: 151.1071.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "416/416 [==============================] - 0s 1ms/step - loss: 152.7461 - mse: 150.9334\n",
      "INFO:tensorflow:Assets written to: final_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history=best_model.fit(X_train, y_train, epochs=num_epochs, callbacks=get_callbacks('best_model'))\n",
    "best_model.save('final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92b634c-b178-45e7-ab01-4296e8d14edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 727us/step - loss: 155.3103 - mse: 153.4928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 155.3102569580078, 'mse': 153.49281311035156}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = best_model.evaluate(X_test, y_test)\n",
    "dict(zip(best_model.metrics_names, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee1d5194-9bcf-4a91-9a82-b01851aece84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.585, -10.585,  19.415, ...,  13.415,   4.415, -14.585],\n",
       "       [ -4.278, -13.278,  16.722, ...,  10.722,   1.722, -17.278],\n",
       "       [-11.098, -20.098,   9.902, ...,   3.902,  -5.098, -24.098],\n",
       "       ...,\n",
       "       [-17.083, -26.083,   3.917, ...,  -2.083, -11.083, -30.083],\n",
       "       [-14.909, -23.909,   6.091, ...,   0.091,  -8.909, -27.909],\n",
       "       [-16.07 , -25.07 ,   4.93 , ...,  -1.07 , -10.07 , -29.07 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_model.predict(X_test)\n",
    "pred - np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27437b76-8de4-4243-8357-0bdb09196f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_pred, y_actual):\n",
    "    \"\"\"\n",
    "    returns evaluation metrics for the model:\n",
    "    Accuracy, F1 Score, R Squre, RMSe\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    f1score = 0\n",
    "    rmse = 0\n",
    "    r_sqaure = 0\n",
    "    \n",
    "    if len(y_pred) != len(y_actual):\n",
    "        print('predicted and actual length not equal')\n",
    "        \n",
    "    else:\n",
    "        len_y = len(y_pred)\n",
    "        \n",
    "        y_pred_bool =  y_pred >= 0\n",
    "        y_actual_bool =  y_actual >= 0\n",
    "        f1score = f1_score(y_actual_bool, y_pred_bool, average='binary')\n",
    "        acc = accuracy_score(y_actual_bool, y_pred_bool)\n",
    "        \n",
    "        rmse = np.sqrt(mse(y_actual, y_pred))\n",
    "        r_sqaure = r2_score(y_actual, y_pred)\n",
    "        \n",
    "    df_evaluation = pd.DataFrame({'Accuracy': pd.Series(acc),\n",
    "                                 'F1 Score': pd.Series(f1score),\n",
    "                                 'R Square': pd.Series(r_sqaure),\n",
    "                                 'RMSE': pd.Series(rmse)})\n",
    "    return(df_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e05168ee-5361-48c5-b281-af209ea0e920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>R Square</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.703106</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>12.389223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 Score  R Square       RMSE\n",
       "0  0.629396  0.703106  0.109798  12.389223"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(pred, np.array(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
